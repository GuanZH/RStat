glm.fit = glm(speed~dist, data=cars)
cv.test = cv.glm(cars, glm.fit, K=5)
cv.test
dim(cars)
cv.test$delta
plot(cv.error5~degree)
cv.error5
args(cv.glm)
data("cars", package = "caret")
install.packages("caret")
library("caret")
install.packages("caret")
install.packages("caret")
library("caret")
data("cars", package = "caret")
glimpse(cars)
library(dplyr)
glimpse(cars)
select(cars, -Doors, -Chevy, -sedan) %>%  # 去除掉Doors，chevy，sedan变量
lm(Price ~ Milage + Cylinder + Cruise + Sound + Leather + Buick + Cadillac + Pontiac + Saab + Saturn + convertible + coupe + hatchback + wagon, data = .) # 对模型进行线性拟合
select(cars, -Doors, -Chevy, -sedan) %>%  # 去除掉Doors，chevy，sedan变量
lm(Price ~ Mileage + Cylinder + Cruise + Sound + Leather + Buick + Cadillac + Pontiac + Saab + Saturn + convertible + coupe + hatchback + wagon, data = .) # 对模型进行线性拟合
# 使用modelr package进行CV测试
cars_cv <- cars %>%
select(-Doors, -Chevy, -sedan) %>% # 同上去除3个变量
crossv_kfold(10) # CV K-fold K = 10，把模型分成10份
# 使用modelr package进行CV测试
cars_cv <- cars %>%
select(-Doors, -Chevy, -sedan) %>% # 同上去除3个变量
crosscv_kfold(10) # CV K-fold K = 10，把模型分成10份
# 使用modelr package进行CV测试
cars_cv <- cars %>%
select(-Doors, -Chevy, -sedan) %>% # 同上去除3个变量
cross_kfold(10) # CV K-fold K = 10，把模型分成10份
install.packages("modelr")
library("modelr")
# 使用modelr package进行CV测试
cars_cv <- cars %>%
select(-Doors, -Chevy, -sedan) %>% # 同上去除3个变量
crossv_kfold(10) # CV K-fold K = 10，把模型分成10份
cars_cv # 分割的数据集
args(crossv_kfold)
cars_cv # 分割的数据集
cars_cv %>%
mutate(train = map(train, as_tibble)) %>% # 把每个train转化为dataframe，然后给定义变量train
mutate(model = map(train, ~ lm(Price ~ Mileage + Cylinder + Cruise + Sound + Leather + Buick + Cadillac + Pontiac + Saab + Saturn + convertible + coupe + hatchback + wagon,  data = .))) %>% # 对每个train，做线性回归拟合
mutate(rmse = map2_dbl(model, test, rmse)) %>%
select(.id, rmse)
library(purrr)
cars_cv %>%
mutate(train = map(train, as_tibble)) %>% # 把每个train转化为dataframe，然后给定义变量train
mutate(model = map(train, ~ lm(Price ~ Mileage + Cylinder + Cruise + Sound + Leather + Buick + Cadillac + Pontiac + Saab + Saturn + convertible + coupe + hatchback + wagon,  data = .))) %>% # 对每个train，做线性回归拟合
mutate(rmse = map2_dbl(model, test, rmse)) %>%
select(.id, rmse)
# 该方法同上
ten_fold <- function(x) {
x %>%
mutate(model = map(train, ~ lm(Price ~ Mileage + Cylinder + Cruise + Sound + Leather + Buick + Cadillac + Pontiac + Saab + Saturn + convertible + coupe + hatchback + wagon, data = .))) %>%
mutate(rmse = map2_dbl(model, test, rmse)) %>%
select(.id, rmse)
}
microbenchmark::microbenchmark(ten_fold(cars_cv))
library(modelr)
set.seed(1)  # Run to replicate this post
folds <- crossv_kfold(mtcars, k = 5)
folds
mtcars
dim(mtcars)
folds$train
dim(mtcars)
folds$train
folds$train$1
folds$train
View(folds)
folds$train$`5`
folds$train$`5`$data
folds$test$`1`$data
folds$test[[1]]
lm(mpg~., data=mtcars)
library(dplyr)
library(purrr)
folds <- folds %>%
mutate(model = map(train, ~ lm(mpg ~ ., data = .))) # 对folds里面5个训练集分别进行拟合
folds
folds$model[[1]] %>% summary()
folds %>% mutate(predicted = map2(model, test,  ))
library(dplyr)
library(purrr)
folds <- folds %>%
mutate(model = map(train, ~ lm(mpg ~ ., data = .))) # 对folds里面5个训练集分别进行拟合，并放到新的变量model中
folds
folds$model[[1]] %>% summary() # 比如看训练集1的模型1
folds %>% mutate(predicted = map2(model, test,  ))
args(map2)
?map2
folds %>% mutate(predicted = map2(model, test,`+`  ))
folds %>% mutate(predicted = map2(model, test,  ))
folds %>% mutate(predicted = map2(model, test, add_residuals ))
folds %>% mutate(predicted = map2(model, test, ~ ))
folds %>% mutate(predicted = map2(model, test, ~ ))
folds %>%
mutate(predicted = map2(model, test, ~ ))
folds %>%
mutate(predicted = map2(model, test, ~ )))
folds %>%
mutate(predicted = map2(model, test, ~ ))
folds %>%
mutate(predicted = map2(model, test, ~ augment(.x, newdata = .y)))
library(broom)
folds %>%
mutate(predicted = map2(model, test, ~ augment(.x, newdata = .y)))
library(tidyr)
folds %>%
mutate(predicted = map2(model, test, ~ augment(.x, newdata = .y))) %>%
unnest(predicted)
# 同上
predicted <- folds %>% unnest(map2(model, test, ~ augment(.x, newdata = .y)))
predicted
# 同上
predicted <- folds %>% unnest(map2(model, test, ~ augment(.x, newdata = .y)))
# 计算残差
predicted <- predicted %>%
mutate(residual = .fitted - mpg)
# 绘图
library(ggplot2)
predicted %>%
ggplot(aes(mpg, residual)) +
geom_hline(yintercept = 0) +
geom_point() +
stat_smooth(method = "loess") +
theme_minimal()
# 分析结果
rs <- predicted %>%
group_by(.id) %>%
summarise(sst = sum((mpg - mean(mpg)) ^ 2), # Sum of Squares Total
sse = sum(residual ^ 2),          # Sum of Squares Residual/Error
r.squared = 1 - sse / sst         # Proportion of variance accounted for
)
rs
rs %>%
ggplot(aes(r.squared, fill  = .id)) +
geom_histogram() +
geom_vline(aes(xintercept = mean(r.squared)))  # Overall mean
data(Auto)
data(Auto)
cv.error1 = rep(0,5)
for(d in degree){
glm.fit = glm(speed~poly(dist, d), data=cars)
cv.error1[d] = cv.glm(cars,glm.fit)$delta[1]
}
library("boot")
require(boot)
library(MASS)
plot(speed~dist, data=cars, main = "Cars" ,
xlab = "Stopping Distance", ylab = "Speed")
data(cars)
library("boot")
require(boot)
library(MASS)
data(cars)
plot(speed~dist, data=cars, main = "Cars" ,
xlab = "Stopping Distance", ylab = "Speed")
plot(speed~dist, data=cars, main = "Cars" ,
xlab = "Stopping Distance", ylab = "Speed")
cars
detach(cars)
data(cars)
library("boot")
require(boot)
library(MASS)
data(cars)
plot(speed~dist, data=cars, main = "Cars" ,
xlab = "Stopping Distance", ylab = "Speed")
install.packages("e1071","dosNOW","ipred","xgboost")
install.packages("e1071","doSNOW","ipred","xgboost")
install.packages("e1071","ipred","xgboost")
install.packages(c("e1071","ipred","xgboost","doSNOW"))
install.packages(c("e1071", "ipred", "xgboost", "doSNOW"))
library(e1071)
library(ipred)
library(xgboost)
library(caret)
library(doSNOW)
train <- read.csv("train.csv")
View(train)
# 读取数据，对缺失值进行插入
table(train$Embarked)
train$Embarked[train$Embarked==""] <- "S"
# 对age进行处理
summary(train$Age)
train$MissingAge <- ifelse(is.na(train$Age), "Y","N")
# 总和家庭成员数量
train$Familysize <- 1+train$SibSp + train$Parch
# install.packages(c("e1071","ipred","xgboost","doSNOW"))
library(e1071)
library(ipred)
library(xgboost)
library(caret)
library(doSNOW)
train <- read.csv("train.csv")
View(train)
# 读取数据，对缺失值进行插入Embarked插入最多的S
table(train$Embarked)
train$Embarked[train$Embarked==""] <- "S"
# 对age进行处理
summary(train$Age)
train$MissingAge <- ifelse(is.na(train$Age), "Y","N")
# 总和家庭成员数量
train$Familysize <- 1+train$SibSp + train$Parch
# 对变量因子化
train$Survived <- as.factor(train$Survived)
train$Pclass <- as.factor(train$Pclass)
train$Sex <- as.factor(train$Sex)
train$Embarked <- as.factor(train$Embarked)
train$MissingAge <- as.factor(train$MissingAge)
# 对变量因子化
train$Survived <- as.factor(train$Survived)
train$Pclass <- as.factor(train$Pclass)
train$Sex <- as.factor(train$Sex)
train$Embarked <- as.factor(train$Embarked)
train$MissingAge <- as.factor(train$MissingAge)
# 选取需要的变量
features <- c("Survived","Pclass","Sex","Age","SibSp","Parch","Fare","Embarked","MissingAge")
train <- train[,features]
dummy.vars <- dummyVars(~.,data=train[,-1])
dummy.vars
View(dummy.vars)
dummy.vars$vars
dummy.vars$call
?dummyVars
levels(when$time) <- list(morning="morning",
afternoon="afternoon",
night="night")
when <- data.frame(time = c("afternoon", "night", "afternoon",
"morning", "morning", "morning",
"morning", "afternoon", "afternoon"),
day = c("Mon", "Mon", "Mon",
"Wed", "Wed", "Fri",
"Sat", "Sat", "Fri"))
levels(when$time) <- list(morning="morning",
afternoon="afternoon",
night="night")
levels(when$day) <- list(Mon="Mon", Tue="Tue", Wed="Wed", Thu="Thu",
Fri="Fri", Sat="Sat", Sun="Sun")
## Default behavior:
model.matrix(~day, when)
mainEffects <- dummyVars(~ day + time, data = when)
mainEffects
predict(mainEffects, when[1:3,])
when <- data.frame(time = c("afternoon", "night", "afternoon",
"morning", "morning", "morning",
"morning", "afternoon", "afternoon"),
day = c("Mon", "Mon", "Mon",
"Wed", "Wed", "Fri",
"Sat", "Sat", "Fri"))
when
mainEffects <- dummyVars(~ day + time, data = when)
mainEffects
predict(mainEffects, when[1:3,])
dummy.vars <- dummyVars(~.,data=train[,-1])
train.dummy <- predict(dummy.vars, train[,-1])
View(train.dummy)
pre.process <- preProcess(train.dummy, method="bagImpute")
Imputed.data <- predict(pre.process, train.dummy)
View(Imputed.data)
train$Age <- imputed.data[,6]
train$Age <- Imputed.data[,6]
View(train)
View(pre.process)
indexes <- createDataPartition(train$Survived, times=1, p=0.7, list = FALSE)
titanic.train <- train[indexes,]
titanic.test <- train[-indexes,]
prop.table(table(train$Survived))
table(train$Survived)
prop.table(table(titanic.train$Survived))
prop.table(table(titanic.test$Survived))
prop.table(table(titanic.train$Survived))
table(titanic.train$Survived
)
tune.grid <- expand.grid(eta = c(0.05,0.075,0.1),
nrounds = c(50.75,100),
max_depth = 6:8,
min_child_weight = c(2.0,2.25,2.5), colsample_bytree = c(0.3,0.4,0.5),gamma=0,subsample =1)
View(tune.grid)
train.control <- trainControl(method="repeatedcv",number=10, repeats = 3, search="grid")
tune.grid <- expand.grid(eta = c(0.05,0.075,0.1),
nrounds = c(50.75,100),
max_depth = 6:8,
min_child_weight = c(2.0,2.25,2.5), colsample_bytree = c(0.3,0.4,0.5),gamma=0,subsample =1)
cl <- makeCluster(2,type="SOCK") # 数字根据计算机能力设置，一般设置小一点
registerDoSNOW(cl) # 使得caret识别出平行训练的模式
caret.cv <- train(Survived ~., data=titanic.train,
method = "xgbTree",
tuneGrid = tune.grid,
trControl = train.control)
devtools::install_github('topepo/caret/pkg/caret')
devtools::install_github('topepo/caret/pkg/caret')
install.packages(c("crul", "memisc"))
detach("package:caret", unload=TRUE)
remove.packages("caret")
install.packages("caret", dependencies = c("Depends", "Suggests"))
library(caret)
devtools::install_github('topepo/caret/pkg/caret')
math <- c(88,95,85, ,76,69,78, ,70,68)
math <- c(88,95,85,NA,76,69,78,NA,70,68)
math
math[is.na(math)]
math[!is.na(math)]
# 给定一个数据集，如何插入缺失值呢
# 一般的方法是用均值或者众值插入
math <- c(88,95,85,NA,76,69,78,NA,70,68)
m1 <- math[is.na(math)]
m2 <- math[!is.na(math)]
math1 <- math
math2 <- math
math1[is.na(math1)] <- mean(m2)
math2[is.na(math2)] <- median(m2)
math1
math2
rm(list=ls())
var1 <- c(19,13,NA,17,5,16,NA,20,18,12,25,12,3022)
var2 <- c(49.76682,53.15736,50.19383,48.79405,NA,51.04863,53.56600,51.22467,47.98000,NA,44.58380,50.29183,52.76665,NA)
dat <- data.frame(var1,var2)
length(var1)
length(var2)
length(var1)
var1
var1 <- c(19,13,NA,17,5,16,NA,20,18,12,25,12,30,22)
var2 <- c(49.76682,53.15736,50.19383,48.79405,NA,51.04863,53.56600,51.22467,47.98000,NA,44.58380,50.29183,52.76665,NA)
dat <- data.frame(var1,var2)
dat
hist(dat$va1)
hist(dat$var1)
hist(dat$var2)
dat$var1[is.na(dat$var1)]
dat$var1[is.na(dat$var1)] <- mean(dat$var1[!is.na(dat$var1)])
dat$var2[is.na(dat$var2)] <- median(dat$var2[!is.na(dat$var2)])
dat
x <- c(1:10)
y <- c(11,12,18,14,17,NA,NA,19,NA,27)
z <- c(19,11,2,14,20,4,9,10,18,1)
w <- c(1,4,7,10,3,5,7,6,6,9)
dat <- data.frame(x,y,z,w)
dat
which(dat)
which(dat[2])
args(which)
which(is.na(dat))
dat
which(is.na(dat))
dat[which(is.na(dat))]
dat[which(is.na(dat)),]
dat
dat[which(is.na(dat)),]
dat[which(is.na(dat)),z]
dat[which(is.na(dat)),x]
dat[which(is.na(dat))]
dat[which(is.na(dat)),]
x <- c(1:10)
y <- c(11,12,18,14,17,NA,NA,19,NA,27)
z <- c(19,11,2,14,20,4,9,10,18,1)
w <- c(1,4,7,10,3,5,7,6,6,9)
dat <- data.frame(x,y,z,w)
dat
dat[which(is.na(dat)),]
cor(dat)
cor(dat,use="complete.obs")
symnum(cor(dat,use="complete.obs"))
cor(dat,use="complete.obs") #如果数据有缺失值，use可以自动排除掉缺失值
cor(dat,use="complete.obs") #如果数据有缺失值，use可以自动排除掉缺失值
symnum(cor(dat,use="complete.obs"))
y[which(is.na(y))]
Ind <- function(t){
x <- dim(length(t))
x[which(is.na(t))] = 1
x[which(!is.na(t))] = 0
return(x)
}
dat$I <- Ind(dat$y)
dat
Ind <- function(t){
x <- dim(length(t))
x[which(!is.na(t))] = 1
x[which(is.na(t))] = 0
return(x)
}
dat$I <- Ind(dat$y)
dat
lm(y~x,data=dat)
summary(lm(y~x,data=dat))
for (i in 1:nrow(dat)){
if dat$I[i] == 0 {
for (i in 1:nrow(dat)) {
if dat$I[i] == 0 {
for (i in 1:nrow(dat)) {
if (dat$I[i] == 0) {
dat$y[i] = 9.7432 + 1.509 * dat$x[i]
}
}
dat
movies <- read.csv("HollywoodsMostProfitableStories.csv")
str(movies)
head(movies)
summary(movies)
movies[which(is.na(movies))]
which(is.na(movies))
library(VIM)
install.packages("VIM")
library("VIM")
movie1 <- kNN(movies, variable=c("Genre","Profitability"), k = 6)
summary(movie1)
movie2 <- kNN(movies)
summary(movie2)
boxplot(x)
x <- c(sample(x=1:20, size=40, replace = TRUE), 65,80)
boxplot(x)
boxplot.stats(x)
x1 <- x
length(x1)
boxplot.stats(x)
bench <- 17.75 + 1.5 * IQR(x1)
x1[x1 > bench]
x1[x1 < bench]
summary(x1)
x1 <- x1[x1 < bench]
summary(x1)
boxplot(x1)
x <- c(sample(x=1:20, size=40, replace = TRUE), 65,80)
bench <- 17.75 + 1.5 * IQR(x1) # Q3 + 1.5 * IQR
bench
x[x>bench]
x[x>bench] <- bench
x
summary(x)
boxplot(x)
x <- c(sample(x=1:20, size=40, replace = TRUE), 65,80)
summary(x)
log.x <- log(x)
summary(log.x)
boxplot(x)
boxplot(log.x)
boxplot(x)
boxplot(log.x)
data(iris)
summary(iris)
install.packages("MICE")
install.packages("mice")
library("mice")
iris.mis <- prodNA(iris,noNA=0.1)
install.packages("missForest")
library("missForest")
iris.mis <- prodNA(iris,noNA=0.1)
summary(iris.mis)
summary(iris.mis)
iris.mis <- subset(iris.mis, select = -c(Species))
summary(iris.mis)
md.pattern(iris.mis)
library(VIM)
mice_plot <- aggr(iris.mis, col=c('navyblue','yellow'),
numbers=TRUE,
sortVars=TRUE,
labels = names(iris.mis),
cex.axis=.8,
gap=3,
ylab=c("missing data","pattern"))
imputed_Data <- mice(iris.mis,m=5,maxit=5,method='pmm',seed=500) #m=5代表使用5个数据集，maxit=5代表迭代次数，method代表插值方法，这里使用predictive mean matching
summary(imputed_Data)
imputed_Data$imp$Sepal.Width
completeData <- complete(imputed_Data,2)
completeData
summary(iris.mis)
fit <- with(data=imputed_Data, exp = lm(Sepal.Width~Sepal.Length+Petal.Width))
combine <- pool(fit)
summary(combine)
install.packages("Amelia")
rm(list=ls())
library(Amelia)
data("iris")
iris.mis <- prodNA(iris, noNA = 0.1)
summary(iris.mis)
amelia_fit <- amelia(iris.mis, m=5, parallel = "multicore", noms = "Species")
amelia_fit$imputations[[1]]
library(missForest)
rm(list=ls())
data(iris)
iris.imp <- missForest(iris.mis)
iris.mis <- prodNA(iris, noNA=0.1)
iris.imp <- missForest(iris.mis)
iris.imp$ximp
iris.imp$OOBerror
iris.err <- mixError(iris.imp$ximp, iris.ims,iris)
iris.err <- mixError(iris.imp$ximp, iris.mis,iris)
iris.err
library(Hmisc)
rm(list=ls())
library(Hmisc)
data(iris)
iris.mis <- prodNA(iris, noNA=0.1)
iris.mis$imputed_age <- with(iris.mis,impute(Sepal.Length, mean))
iris.mis
impute_arg <- aregImpute(~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width +
Species, data = iris.mis, n.impute = 5)
impute_arg
impute_arg$imputed$Sepal.Length
rm(list=ls())
library(Hmisc)
data(iris)
iris.mis <- prodNA(iris, noNA=0.1)
install.packages("mi")
library(mi)
mi_data <- mi(iris.mis, seed=335)
summary(mi_data)
